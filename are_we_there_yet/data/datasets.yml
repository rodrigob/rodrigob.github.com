---
Classification:
- :group: Classification
  :name: MNIST
  :evaluation_units: error %
  :description: ! "[Classify handwriten digits](http://yann.lecun.com/exdb/mnist/).
    \nSome additional results are available on the [original dataset page](http://yann.lecun.com/exdb/mnist/)."
  :figure_url: mnist.png
- :group: Classification
  :name: CIFAR-10
  :evaluation_units: precision %
  :description: Classify [32x32 colour images](http://www.cs.toronto.edu/~kriz/cifar.html).
  :figure_url: cifar_10.png
- :group: Classification
  :name: CIFAR-100
  :evaluation_units: precision %
  :description: Classify [32x32 colour images](http://www.cs.toronto.edu/~kriz/cifar.html).
  :figure_url: cifar_100.png
- :group: Classification
  :name: STL-10
  :evaluation_units: precision %
  :description: Similar to CIFAR-10 but with 96x96 images. [Original dataset website](http://www.stanford.edu/~acoates/stl10/).
  :figure_url: stl_10.png
- :group: Classification
  :name: SVHN
  :evaluation_units: error %
  :description: ! '[The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers).


    SVHN is a real-world image dataset for developing machine learning and object
    recognition algorithms with minimal requirement on data preprocessing and formatting.
    It can be seen as similar in flavor to MNIST (e.g., the images are of small cropped
    digits), but incorporates an order of magnitude more labeled data (over 600,000
    digit images) and comes from a significantly harder, unsolved, real world problem
    (recognizing digits and numbers in natural scene images). SVHN is obtained from
    house numbers in Google Street View images.

'
  :figure_url: !ruby/string
    str: http://ufldl.stanford.edu/housenumbers/32x32eg.png
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://ufldl.stanford.edu/housenumbers/32x32eg.png
      background: 9
      mode: 0
- :group: Classification
  :name: ILSVRC2012 task 1
  :evaluation_units: Error (5 guesses)
  :description: ! '1000 categories [classification challenge](http://www.image-net.org/challenges/LSVRC/2012/index).
    With tens of thousands of training, validation and testing images.


    See this interesting [comparative analysis](http://www.image-net.org/challenges/LSVRC/2012/analysis/).'
  :figure_url: ilsvrc2012_task1.png
  :external_results_url: !ruby/string
    str: http://www.image-net.org/challenges/LSVRC/2012/results.html#t1
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.image-net.org/challenges/LSVRC/2012/results.html#t1
      background: 9
      mode: 0
Detection:
- :group: Detection
  :name: Pascal VOC 2007 comp3
  :evaluation_units: mAP
  :description: Pascal VOC 2007 is commonly used because the test set has been realased.
    comp3 is the objects detection competition.
  :figure_url: pascal_voc_2007.png
- :group: Detection
  :name: Pascal VOC 2010 comp3
  :evaluation_units: mAP
  :description: Pascal VOC 2010 version of the challenge. comp3 is the objects detection
    competition.
  :figure_url: pascal_voc_2010.png
- :group: Detection
  :name: Pascal VOC 2011/2012 comp3
  :evaluation_units: mAP
  :description: Last Pascal VOC challenge instance.
  :figure_url: pascal_voc_2012.png
- :group: Detection
  :name: Caltech Pedestrians USA
  :evaluation_units: average miss-rate %
  :description: ! '[Project website](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/).'
  :figure_url: !ruby/string
    str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/peds02_web.jpg
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/files/peds02_web.jpg
      background: 9
      mode: 0
  :external_results_url: !ruby/string
    str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/UsaTestRocReasonable.pdf
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/UsaTestRocReasonable.pdf
      background: 9
      mode: 0
- :group: Detection
  :name: INRIA Persons
  :evaluation_units: average miss-rate %
  :description: ! 'Evaluated using the [Caltech Pedestrians toolkit](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/).

    [Original dataset website](http://pascal.inrialpes.fr/data/human/).'
  :figure_url: inria_persons.png
  :external_results_url: !ruby/string
    str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/InriaTestRocReasonable.pdf
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/InriaTestRocReasonable.pdf
      background: 9
      mode: 0
- :group: Detection
  :name: ! 'ETH Pedestrian '
  :evaluation_units: average miss-rate %
  :description: ! 'Evaluated using the [Caltech Pedestrians toolkit](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/).

    Only left images used.

    [Original dataset website](http://www.vision.ee.ethz.ch/~aess/dataset/).'
  :figure_url: eth_pedestrian.png
  :external_results_url: !ruby/string
    str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/ETHRocReasonable.pdf
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/ETHRocReasonable.pdf
      background: 9
      mode: 0
- :group: Detection
  :name: TUD-Brussels Pedestrian
  :evaluation_units: average miss-rate %
  :description: ! 'Evaluated using the [Caltech Pedestrians toolkit](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/).

    [Original dataset website](http://www.d2.mpi-inf.mpg.de/tud-brussels).'
  :figure_url: !ruby/string
    str: http://www.d2.mpi-inf.mpg.de/sites/default/files/datasets/tud-brussels/teaser.png
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.d2.mpi-inf.mpg.de/sites/default/files/datasets/tud-brussels/teaser.png
      background: 9
      mode: 0
  :external_results_url: !ruby/string
    str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/TudBrusselsRocReasonable.pdf
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/TudBrusselsRocReasonable.pdf
      background: 9
      mode: 0
- :group: Detection
  :name: Daimler Pedestrian
  :evaluation_units: average miss-rate %
  :description: ! 'Evaluated using the [Caltech Pedestrians toolkit](http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/).

    [Original dataset website](http://www.science.uva.nl/research/isla/downloads/pedestrians/).'
  :figure_url: !ruby/string
    str: http://www.science.uva.nl/research/isla/downloads/pedestrians/assets/images/ped_det_benchmark.jpg
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.science.uva.nl/research/isla/downloads/pedestrians/assets/images/ped_det_benchmark.jpg
      background: 9
      mode: 0
  :external_results_url: !ruby/string
    str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/DaimlerRocReasonable.pdf
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.vision.caltech.edu/Image_Datasets/CaltechPedestrians/rocs/DaimlerRocReasonable.pdf
      background: 9
      mode: 0
- :group: Detection
  :name: KITTI Vision Benchmark
  :evaluation_units: average recall %
  :description: A rich dataset to evaluate multiple computer vision tasks, including
    cars, pedestrian and bycicles detection.
  :figure_url: !ruby/string
    str: http://www.cvlibs.net/datasets/kitti/video/kitti_trailer.jpg
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.cvlibs.net/datasets/kitti/video/kitti_trailer.jpg
      background: 9
      mode: 0
  :external_results_url: !ruby/string
    str: http://www.cvlibs.net/datasets/kitti/eval_object.php
    background: 9
    mode: 0
    uncolorized: !ruby/string
      str: http://www.cvlibs.net/datasets/kitti/eval_object.php
      background: 9
      mode: 0
Pose estimation:
- :group: Pose estimation
  :name: Leeds Sport Poses
  :evaluation_units: PCP %
  :description: ! '[2000 poses anotated pictures](http://www.comp.leeds.ac.uk/mat4saj/lsp.html)
    from Flickr. From a selected set of activities and with the person at the center
    of the pictures.'
  :figure_url: leeds_sport_poses.jpg
Semantic labeling:
- :group: Semantic labeling
  :name: MSRC-21
  :evaluation_units: precision % per-class / (and) per-pixel
  :description: ! "One of the oldest and classic dataset for semantic labelling.\n21
    different categories of surfaces are considered.\nDespite the innacuracies in
    the annotations and how unbalanced the classes are, this dataset still is commonly
    used as reference point.\nNote that here we consider the [original annotations](http://jamie.shotton.org/work/data.html)
    (where most results are published), not the [cleaned-up version](http://www.cs.cmu.edu/~tmalisie/projects/bmvc07).
    \n\n\nThe results are reported per-class and per-pixel (this is sometimes called
    \"average\" and \"global\" result, respectively).\n\n\n[Original dataset website](http://jamie.shotton.org/work/data.html)\n"
  :figure_url: msrc_21.png
